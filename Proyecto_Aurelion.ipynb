{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56151ae",
   "metadata": {},
   "source": [
    "## üì• 1. Importaci√≥n y Carga de los 4 Dataframes Limpios\n",
    "\n",
    "Cargaremos los 4 dataframes desde los notebooks ya ejecutados. Esto requiere que los notebooks anteriores hayan sido ejecutados y los dataframes est√©n disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "27c8fb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerias cargadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Mostrar opciones de pandas para debugging\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print('Librerias cargadas correctamente.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "auto_carga_datos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK ] Clientes                 -> (100, 5) | fuente: db\\processed\\clientes_limpio.csv\n",
      "[OK ] Ventas (cabecera)        -> (120, 6) | fuente: db\\processed\\ventas_limpio.csv\n",
      "[OK ] Detalle de ventas        -> (343, 6) | fuente: db\\processed\\detalle_ventas_limpio.csv\n",
      "[OK ] Productos                -> (100, 4) | fuente: db\\processed\\productos_limpio.csv\n",
      "\n",
      "Dataframes limpios disponibles en memoria.\n"
     ]
    }
   ],
   "source": [
    "# Configuracion de rutas y artefactos intermedios (ETL)\n",
    "PROJECT_DIR = Path.cwd()\n",
    "DATA_RAW_DIR = PROJECT_DIR / 'db' / 'raw'\n",
    "if not DATA_RAW_DIR.exists():\n",
    "    DATA_RAW_DIR = PROJECT_DIR / 'db'\n",
    "\n",
    "DATA_PROCESSED_DIR = PROJECT_DIR / 'db' / 'processed'\n",
    "DATA_FINAL_DIR = PROJECT_DIR / 'db' / 'final'\n",
    "DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_SPECS = {\n",
    "    'df_clientes_True': {\n",
    "        'label': 'Clientes',\n",
    "        'raw': 'clientes.xlsx',\n",
    "        'processed': 'clientes_limpio.csv',\n",
    "        'parse_dates': ['fecha_alta']\n",
    "    },\n",
    "    'df_Ventas_True': {\n",
    "        'label': 'Ventas (cabecera)',\n",
    "        'raw': 'ventas.xlsx',\n",
    "        'processed': 'ventas_limpio.csv',\n",
    "        'parse_dates': ['fecha']\n",
    "    },\n",
    "    'df_detalle_ventas_True': {\n",
    "        'label': 'Detalle de ventas',\n",
    "        'raw': 'detalle_ventas.xlsx',\n",
    "        'processed': 'detalle_ventas_limpio.csv',\n",
    "        'parse_dates': []\n",
    "    },\n",
    "    'df_productos_True': {\n",
    "        'label': 'Productos',\n",
    "        'raw': 'productos.xlsx',\n",
    "        'processed': 'productos_limpio.csv',\n",
    "        'parse_dates': []\n",
    "    }\n",
    "}\n",
    "\n",
    "def _read_from_path(file_path, spec):\n",
    "    suffix = file_path.suffix.lower()\n",
    "    if suffix in {'.xlsx', '.xls'}:\n",
    "        return pd.read_excel(file_path, parse_dates=spec.get('parse_dates') or [])\n",
    "    if suffix == '.csv':\n",
    "        return pd.read_csv(file_path, parse_dates=spec.get('parse_dates') or [])\n",
    "    raise ValueError(f'No hay lector definido para {file_path}')\n",
    "\n",
    "def load_clean_dataframe(var_name, spec):\n",
    "    processed_path = DATA_PROCESSED_DIR / spec['processed']\n",
    "    if processed_path.exists():\n",
    "        df = _read_from_path(processed_path, spec)\n",
    "        print(f\"[OK ] {spec['label']:<24} -> {df.shape} | fuente: {processed_path.relative_to(PROJECT_DIR)}\")\n",
    "        return df\n",
    "    raw_path = DATA_RAW_DIR / spec['raw']\n",
    "    if not raw_path.exists():\n",
    "        raise FileNotFoundError(f\"No se encontro la fuente esperada: {raw_path}\")\n",
    "    df = _read_from_path(raw_path, spec)\n",
    "    df.to_csv(processed_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"[NEW] {spec['label']:<24} -> {df.shape} | generado desde {raw_path.relative_to(PROJECT_DIR)}\")\n",
    "    print(f\"      Artefacto intermedio guardado en {processed_path.relative_to(PROJECT_DIR)}\")\n",
    "    return df\n",
    "\n",
    "loaded_frames = {var: load_clean_dataframe(var, spec) for var, spec in DATA_SPECS.items()}\n",
    "globals().update(loaded_frames)\n",
    "print(\"\\nDataframes limpios disponibles en memoria.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe5d5f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK  Clientes                       -> (100, 5) | archivo: OK\n",
      "OK  Ventas (cabecera)              -> (120, 6) | archivo: OK\n",
      "OK  Detalle de ventas              -> (343, 6) | archivo: OK\n",
      "OK  Productos                      -> (100, 4) | archivo: OK\n",
      "\n",
      "Todos los dataframes limpios estan en memoria.\n"
     ]
    }
   ],
   "source": [
    "# Funcion para verificar y reportar disponibilidad de dataframes\n",
    "def check_dataframes():\n",
    "    missing = []\n",
    "    for var_name, spec in DATA_SPECS.items():\n",
    "        processed_path = DATA_PROCESSED_DIR / spec['processed']\n",
    "        artifact_status = 'OK' if processed_path.exists() else 'PENDIENTE'\n",
    "        if var_name in globals():\n",
    "            df_temp = globals()[var_name]\n",
    "            print(f\"OK  {spec['label']:30s} -> {df_temp.shape} | archivo: {artifact_status}\")\n",
    "        else:\n",
    "            missing.append(spec)\n",
    "            print(f\"X   {spec['label']:30s} -> NO EN MEMORIA | archivo: {artifact_status}\")\n",
    "    if missing:\n",
    "        print(\"\\nAdvertencia: ejecuta los notebooks limp_y_trans_* para regenerar los archivos procesados.\")\n",
    "        return False\n",
    "    print(\"\\nTodos los dataframes limpios estan en memoria.\")\n",
    "    return True\n",
    "\n",
    "# Verificar disponibilidad\n",
    "all_available = check_dataframes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f2981",
   "metadata": {},
   "source": [
    "## üìä 2. Inspecci√≥n de Estructura y Claves\n",
    "\n",
    "Antes de realizar los merges, inspeccionaremos cada dataframe para identificar correctamente las claves primarias (PK) y for√°neas (FK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3354438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üìã ESTRUCTURA DE DATAFRAMES\n",
      "====================================================================================================\n",
      "\n",
      "1. df_clientes_True (PK: id_cliente)\n",
      "--------------------------------------------------------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [id_cliente, nombre_cliente, email, ciudad, fecha_alta]\n",
      "Index: []\n",
      "Columnas: ['id_cliente', 'nombre_cliente', 'email', 'ciudad', 'fecha_alta']\n",
      "Registros: 100\n",
      "\n",
      "2. df_Ventas_True (PK: id_venta | FK: id_cliente)\n",
      "--------------------------------------------------------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [id_venta, fecha, id_cliente, nombre_cliente, email, medio_pago]\n",
      "Index: []\n",
      "Columnas: ['id_venta', 'fecha', 'id_cliente', 'nombre_cliente', 'email', 'medio_pago']\n",
      "Registros: 120\n",
      "\n",
      "3. df_detalle_ventas_True (PK: id_detalle | FK: id_venta, id_producto)\n",
      "--------------------------------------------------------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [id_venta, id_producto, nombre_producto, cantidad, precio_unitario, importe]\n",
      "Index: []\n",
      "Columnas: ['id_venta', 'id_producto', 'nombre_producto', 'cantidad', 'precio_unitario', 'importe']\n",
      "Registros: 343\n",
      "\n",
      "4. df_productos_True (PK: id_producto)\n",
      "--------------------------------------------------------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [id_producto, nombre_producto, categoria, precio_unitario]\n",
      "Index: []\n",
      "Columnas: ['id_producto', 'nombre_producto', 'categoria', 'precio_unitario']\n",
      "Registros: 100\n"
     ]
    }
   ],
   "source": [
    "if all_available:\n",
    "    print('='*100)\n",
    "    print('üìã ESTRUCTURA DE DATAFRAMES')\n",
    "    print('='*100)\n",
    "    \n",
    "    print('\\n1. df_clientes_True (PK: id_cliente)')\n",
    "    print('-'*80)\n",
    "    print(df_clientes_True.head(0))\n",
    "    print(f'Columnas: {list(df_clientes_True.columns)}')\n",
    "    print(f'Registros: {len(df_clientes_True)}')\n",
    "    \n",
    "    print('\\n2. df_Ventas_True (PK: id_venta | FK: id_cliente)')\n",
    "    print('-'*80)\n",
    "    print(df_Ventas_True.head(0))\n",
    "    print(f'Columnas: {list(df_Ventas_True.columns)}')\n",
    "    print(f'Registros: {len(df_Ventas_True)}')\n",
    "    \n",
    "    print('\\n3. df_detalle_ventas_True (PK: id_detalle | FK: id_venta, id_producto)')\n",
    "    print('-'*80)\n",
    "    print(df_detalle_ventas_True.head(0))\n",
    "    print(f'Columnas: {list(df_detalle_ventas_True.columns)}')\n",
    "    print(f'Registros: {len(df_detalle_ventas_True)}')\n",
    "    \n",
    "    print('\\n4. df_productos_True (PK: id_producto)')\n",
    "    print('-'*80)\n",
    "    print(df_productos_True.head(0))\n",
    "    print(f'Columnas: {list(df_productos_True.columns)}')\n",
    "    print(f'Registros: {len(df_productos_True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afbcb4",
   "metadata": {},
   "source": [
    "## üîó 3. Preparaci√≥n: Renombrado de Claves For√°neas\n",
    "\n",
    "En la tabla de detalle de ventas, si existe un nombre diferente para la FK de producto (ej: FK_producto), lo renombramos a `id_producto` para que el merge sea un√≠voco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc66d071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üîß PREPARACI√ìN: Validaci√≥n y renombrado de columnas\n",
      "====================================================================================================\n",
      "\n",
      "‚úì Columna id_producto ya existe en df_detalle_ventas_True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìå Validaci√≥n de Integridad Referencial:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úì FK id_cliente en ventas:\n",
      "OK (67 referencias v√°lidas)\n",
      "‚úì FK id_venta en detalle:\n",
      "OK (120 referencias v√°lidas)\n",
      "‚úì FK id_producto en detalle:\n",
      "OK (95 referencias v√°lidas)\n"
     ]
    }
   ],
   "source": [
    "if all_available:\n",
    "    print('='*100)\n",
    "    print('üîß PREPARACI√ìN: Validaci√≥n y renombrado de columnas')\n",
    "    print('='*100)\n",
    "    \n",
    "    # Verificar y renombrar columna de producto en detalle_ventas si es necesario\n",
    "    if 'FK_producto' in df_detalle_ventas_True.columns:\n",
    "        print('\\n‚úì Renombrando FK_producto ‚Üí id_producto en df_detalle_ventas_True')\n",
    "        df_detalle_ventas_True.rename(columns={'FK_producto': 'id_producto'}, inplace=True)\n",
    "    elif 'id_producto' not in df_detalle_ventas_True.columns:\n",
    "        print('\\n‚ö†Ô∏è  Aviso: No se encontr√≥ FK_producto ni id_producto en detalle_ventas')\n",
    "        print(f'   Columnas disponibles: {list(df_detalle_ventas_True.columns)}')\n",
    "    else:\n",
    "        print('\\n‚úì Columna id_producto ya existe en df_detalle_ventas_True')\n",
    "    \n",
    "    # Validar que todos los FK referencias existan en las PK correspondientes\n",
    "    print('\\n' + '-'*80)\n",
    "    print('üìå Validaci√≥n de Integridad Referencial:')\n",
    "    print('-'*80)\n",
    "    \n",
    "    # FK id_cliente en ventas\n",
    "    clientes_en_ventas = set(df_Ventas_True['id_cliente'].dropna().unique())\n",
    "    clientes_existentes = set(df_clientes_True['id_cliente'].unique())\n",
    "    clientes_huerfanos = clientes_en_ventas - clientes_existentes\n",
    "    print(f'\\n‚úì FK id_cliente en ventas:',)\n",
    "    if not clientes_huerfanos:\n",
    "        print(f'OK ({len(clientes_en_ventas)} referencias v√°lidas)')\n",
    "    else:\n",
    "        print(f'INCONSISTENCIA: {len(clientes_huerfanos)} hu√©rfanos')\n",
    "    \n",
    "    # FK id_venta en detalle\n",
    "    ventas_en_detalle = set(df_detalle_ventas_True['id_venta'].dropna().unique())\n",
    "    ventas_existentes = set(df_Ventas_True['id_venta'].unique())\n",
    "    ventas_huerfanas = ventas_en_detalle - ventas_existentes\n",
    "    print(f'‚úì FK id_venta en detalle:',)\n",
    "    if not ventas_huerfanas:\n",
    "        print(f'OK ({len(ventas_en_detalle)} referencias v√°lidas)')\n",
    "    else:\n",
    "        print(f'INCONSISTENCIA: {len(ventas_huerfanas)} hu√©rfanos')\n",
    "    \n",
    "    # FK id_producto en detalle\n",
    "    productos_en_detalle = set(df_detalle_ventas_True['id_producto'].dropna().unique())\n",
    "    productos_existentes = set(df_productos_True['id_producto'].unique())\n",
    "    productos_huerfanos = productos_en_detalle - productos_existentes\n",
    "    print(f'‚úì FK id_producto en detalle:',)\n",
    "    if not productos_huerfanos:\n",
    "        print(f'OK ({len(productos_en_detalle)} referencias v√°lidas)')\n",
    "    else:\n",
    "        print(f'INCONSISTENCIA: {len(productos_huerfanos)} hu√©rfanos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc2bf7",
   "metadata": {},
   "source": [
    "## üîÄ 4. Merge de Tablas - Consolidaci√≥n de Base Final\n",
    "\n",
    "Realizamos los merges en orden siguiendo la estructura de relaciones:\n",
    "1. `df_clientes_True` ‚Üê merge ‚Üê `df_Ventas_True` (on=id_cliente)\n",
    "2. Resultado ‚Üê merge ‚Üê `df_detalle_ventas_True` (on=id_venta)\n",
    "3. Resultado ‚Üê merge ‚Üê `df_productos_True` (on=id_producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02b8e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üîÄ MERGE - Consolidaci√≥n de Base Final\n",
      "====================================================================================================\n",
      "\n",
      "1Ô∏è‚É£  Merge: df_clientes_True + df_Ventas_True (on=id_cliente)\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Dimensiones resultado: (120, 10)\n",
      "  - Registros: 120\n",
      "  - Columnas: 10\n",
      "\n",
      "2Ô∏è‚É£  Merge: resultado + df_detalle_ventas_True (on=id_venta)\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Dimensiones resultado: (343, 15)\n",
      "  - Registros: 343\n",
      "  - Columnas: 15\n",
      "\n",
      "3Ô∏è‚É£  Merge: resultado + df_productos_True (on=id_producto)\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Dimensiones resultado: (343, 18)\n",
      "  - Registros: 343\n",
      "  - Columnas: 18\n",
      "\n",
      "‚ú® Merge completado exitosamente!\n",
      "‚úì Dimensiones resultado: (343, 18)\n",
      "  - Registros: 343\n",
      "  - Columnas: 18\n",
      "\n",
      "‚ú® Merge completado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "if all_available:\n",
    "    print('='*100)\n",
    "    print('üîÄ MERGE - Consolidaci√≥n de Base Final')\n",
    "    print('='*100)\n",
    "    \n",
    "    print('\\n1Ô∏è‚É£  Merge: df_clientes_True + df_Ventas_True (on=id_cliente)')\n",
    "    print('-'*80)\n",
    "    base_consolidada = df_clientes_True.merge(\n",
    "        df_Ventas_True,\n",
    "        on='id_cliente',\n",
    "        how='inner',  # inner join para evitar clientes sin ventas\n",
    "        validate='1:m'  # 1 cliente : muchas ventas\n",
    "    )\n",
    "    print(f'‚úì Dimensiones resultado: {base_consolidada.shape}')\n",
    "    print(f'  - Registros: {len(base_consolidada)}')\n",
    "    print(f'  - Columnas: {len(base_consolidada.columns)}')\n",
    "    \n",
    "    print('\\n2Ô∏è‚É£  Merge: resultado + df_detalle_ventas_True (on=id_venta)')\n",
    "    print('-'*80)\n",
    "    base_consolidada = base_consolidada.merge(\n",
    "        df_detalle_ventas_True,\n",
    "        on='id_venta',\n",
    "        how='inner',  # inner join para que todo tenga detalle\n",
    "        validate='m:m'  # muchas ventas : muchos detalles\n",
    "    )\n",
    "    print(f'‚úì Dimensiones resultado: {base_consolidada.shape}')\n",
    "    print(f'  - Registros: {len(base_consolidada)}')\n",
    "    print(f'  - Columnas: {len(base_consolidada.columns)}')\n",
    "    \n",
    "    print('\\n3Ô∏è‚É£  Merge: resultado + df_productos_True (on=id_producto)')\n",
    "    print('-'*80)\n",
    "    base_consolidada = base_consolidada.merge(\n",
    "        df_productos_True,\n",
    "        on='id_producto',\n",
    "        how='inner',  # inner join para evitar productos sin venta\n",
    "        validate='m:1'  # muchos detalles : 1 producto\n",
    "    )\n",
    "    print(f'‚úì Dimensiones resultado: {base_consolidada.shape}')\n",
    "    print(f'  - Registros: {len(base_consolidada)}')\n",
    "    print(f'  - Columnas: {len(base_consolidada.columns)}')\n",
    "    \n",
    "    print('\\n‚ú® Merge completado exitosamente!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de60ff8",
   "metadata": {},
   "source": [
    "## üìä 5. Inspecci√≥n de la Base Consolidada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18c57271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üìã INSPECCI√ìN - Base Consolidada\n",
      "====================================================================================================\n",
      "\n",
      "Primeras 5 filas:\n",
      "--------------------------------------------------------------------------------\n",
      "   id_cliente nombre_cliente_x                 email_x      ciudad fecha_alta  id_venta      fecha nombre_cliente_y  \\\n",
      "0           1    Mariana Lopez  mariana.lopez@mail.com  Carlos Paz 2023-01-01        54 2024-03-26    Mariana Lopez   \n",
      "1           1    Mariana Lopez  mariana.lopez@mail.com  Carlos Paz 2023-01-01        54 2024-03-26    Mariana Lopez   \n",
      "2           1    Mariana Lopez  mariana.lopez@mail.com  Carlos Paz 2023-01-01        54 2024-03-26    Mariana Lopez   \n",
      "3           1    Mariana Lopez  mariana.lopez@mail.com  Carlos Paz 2023-01-01        54 2024-03-26    Mariana Lopez   \n",
      "4           1    Mariana Lopez  mariana.lopez@mail.com  Carlos Paz 2023-01-01       105 2024-02-06    Mariana Lopez   \n",
      "\n",
      "                  email_y     medio_pago  id_producto       nombre_producto_x  cantidad  precio_unitario_x  importe  \\\n",
      "0  mariana.lopez@mail.com        tarjeta           65        Cerveza Rubia 1L         1               2423     2423   \n",
      "1  mariana.lopez@mail.com        tarjeta           18      Queso Rallado 150g         2               3444     6888   \n",
      "2  mariana.lopez@mail.com        tarjeta           91     Desodorante Aerosol         3               4690    14070   \n",
      "3  mariana.lopez@mail.com        tarjeta            8  Energ√©tica Nitro 500ml         3               4218    12654   \n",
      "4  mariana.lopez@mail.com  transferencia           13    T√© Verde 20 saquitos         2               2383     4766   \n",
      "\n",
      "        nombre_producto_y  categoria  precio_unitario_y  \n",
      "0        Cerveza Rubia 1L  Alimentos               2423  \n",
      "1      Queso Rallado 150g   Limpieza               3444  \n",
      "2     Desodorante Aerosol  Alimentos               4690  \n",
      "3  Energ√©tica Nitro 500ml   Limpieza               4218  \n",
      "4    T√© Verde 20 saquitos  Alimentos               2383  \n",
      "\n",
      "\n",
      "√öltimas 5 filas:\n",
      "--------------------------------------------------------------------------------\n",
      "     id_cliente nombre_cliente_x                  email_x   ciudad fecha_alta  id_venta      fecha nombre_cliente_y  \\\n",
      "338         100   Agustina Lopez  agustina.lopez@mail.com  Cordoba 2023-04-10        55 2024-01-04   Agustina Lopez   \n",
      "339         100   Agustina Lopez  agustina.lopez@mail.com  Cordoba 2023-04-10        62 2024-05-01   Agustina Lopez   \n",
      "340         100   Agustina Lopez  agustina.lopez@mail.com  Cordoba 2023-04-10        62 2024-05-01   Agustina Lopez   \n",
      "341         100   Agustina Lopez  agustina.lopez@mail.com  Cordoba 2023-04-10        87 2024-04-20   Agustina Lopez   \n",
      "342         100   Agustina Lopez  agustina.lopez@mail.com  Cordoba 2023-04-10        87 2024-04-20   Agustina Lopez   \n",
      "\n",
      "                     email_y     medio_pago  id_producto    nombre_producto_x  cantidad  precio_unitario_x  importe  \\\n",
      "338  agustina.lopez@mail.com             qr           39   Helado Vainilla 1L         4                469     1876   \n",
      "339  agustina.lopez@mail.com  transferencia           47       Garbanzos 500g         4               2939    11756   \n",
      "340  agustina.lopez@mail.com  transferencia           95   Mascarilla Capilar         3               1581     4743   \n",
      "341  agustina.lopez@mail.com             qr           53         Lavandina 1L         2               1664     3328   \n",
      "342  agustina.lopez@mail.com             qr           86  Jugo en Polvo Lim√≥n         2               4090     8180   \n",
      "\n",
      "       nombre_producto_y  categoria  precio_unitario_y  \n",
      "338   Helado Vainilla 1L  Alimentos                469  \n",
      "339       Garbanzos 500g  Alimentos               2939  \n",
      "340   Mascarilla Capilar  Alimentos               1581  \n",
      "341         Lavandina 1L  Alimentos               1664  \n",
      "342  Jugo en Polvo Lim√≥n   Limpieza               4090  \n",
      "\n",
      "\n",
      "Tipos de datos:\n",
      "--------------------------------------------------------------------------------\n",
      "id_cliente                    int64\n",
      "nombre_cliente_x             object\n",
      "email_x                      object\n",
      "ciudad                       object\n",
      "fecha_alta           datetime64[ns]\n",
      "id_venta                      int64\n",
      "fecha                datetime64[ns]\n",
      "nombre_cliente_y             object\n",
      "email_y                      object\n",
      "medio_pago                   object\n",
      "id_producto                   int64\n",
      "nombre_producto_x            object\n",
      "cantidad                      int64\n",
      "precio_unitario_x             int64\n",
      "importe                       int64\n",
      "nombre_producto_y            object\n",
      "categoria                    object\n",
      "precio_unitario_y             int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Valores nulos por columna:\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì NO hay valores nulos en la base consolidada\n",
      "\n",
      "\n",
      "Estad√≠sticas generales:\n",
      "--------------------------------------------------------------------------------\n",
      "Dimensiones: (343, 18)\n",
      "Memoria usada: 0.21 MB\n",
      "Clientes √∫nicos: 67\n",
      "Ventas (id_venta) √∫nicas: 120\n",
      "Detalles de venta √∫nicos: N/A\n",
      "Productos √∫nicos: 95\n",
      "Productos √∫nicos: 95\n"
     ]
    }
   ],
   "source": [
    "if 'base_consolidada' in locals():\n",
    "    print('='*100)\n",
    "    print('üìã INSPECCI√ìN - Base Consolidada')\n",
    "    print('='*100)\n",
    "    \n",
    "    print('\\nPrimeras 5 filas:')\n",
    "    print('-'*80)\n",
    "    print(base_consolidada.head())\n",
    "    \n",
    "    print('\\n\\n√öltimas 5 filas:')\n",
    "    print('-'*80)\n",
    "    print(base_consolidada.tail())\n",
    "    \n",
    "    print('\\n\\nTipos de datos:')\n",
    "    print('-'*80)\n",
    "    print(base_consolidada.dtypes)\n",
    "    \n",
    "    print('\\n\\nValores nulos por columna:')\n",
    "    print('-'*80)\n",
    "    nulls = base_consolidada.isnull().sum()\n",
    "    if nulls.sum() == 0:\n",
    "        print('‚úì NO hay valores nulos en la base consolidada')\n",
    "    else:\n",
    "        print(nulls[nulls > 0])\n",
    "    \n",
    "    print('\\n\\nEstad√≠sticas generales:')\n",
    "    print('-'*80)\n",
    "    print(f'Dimensiones: {base_consolidada.shape}')\n",
    "    print(f'Memoria usada: {base_consolidada.memory_usage(deep=True).sum() / (1024**2):.2f} MB')\n",
    "    print(f'Clientes √∫nicos: {base_consolidada[\"id_cliente\"].nunique()}')\n",
    "    print(f'Ventas (id_venta) √∫nicas: {base_consolidada[\"id_venta\"].nunique()}')\n",
    "    print(f'Detalles de venta √∫nicos: {base_consolidada[\"id_detalle\"].nunique() if \"id_detalle\" in base_consolidada.columns else \"N/A\"}')\n",
    "    print(f'Productos √∫nicos: {base_consolidada[\"id_producto\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b37e7",
   "metadata": {},
   "source": [
    "## üßπ 6. Preprocesamiento y Limpieza Adicional\n",
    "\n",
    "En esta secci√≥n aplicamos transformaciones finales para garantizar que la base est√© lista para an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44bdcdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üßπ PREPROCESAMIENTO - Limpieza y Transformaciones Finales\n",
      "====================================================================================================\n",
      "\n",
      "1Ô∏è‚É£  Detecci√≥n de duplicados\n",
      "--------------------------------------------------------------------------------\n",
      "Filas duplicadas: 0\n",
      "\n",
      "2Ô∏è‚É£  Estandarizaci√≥n de nombres de columnas\n",
      "--------------------------------------------------------------------------------\n",
      "Columnas renombradas:\n",
      "  nombre_cliente_x               ‚Üí nombre_cliente\n",
      "  email_x                        ‚Üí email\n",
      "  nombre_cliente_y               ‚Üí nombre_cliente\n",
      "  email_y                        ‚Üí email\n",
      "  nombre_producto_x              ‚Üí nombre_producto\n",
      "  precio_unitario_x              ‚Üí precio_unitario\n",
      "  nombre_producto_y              ‚Üí nombre_producto\n",
      "  precio_unitario_y              ‚Üí precio_unitario\n",
      "\n",
      "2b  Columnas duplicadas tras el merge\n",
      "--------------------------------------------------------------------------------\n",
      " Columnas eliminadas: ['email', 'nombre_cliente', 'nombre_producto', 'precio_unitario']\n",
      "\n",
      "3Ô∏è‚É£  Reorganizaci√≥n de columnas (orden l√≥gico)\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Columnas reordenadas: 14 columnas\n",
      "  - IDs (PK/FK): 4\n",
      "  - Fechas: 2\n",
      "  - Dinero (precios/importes): 2\n",
      "  - Otros: 6\n",
      "\n",
      "4Ô∏è‚É£  Validaci√≥n de tipos de datos\n",
      "--------------------------------------------------------------------------------\n",
      "id_cliente                  int64\n",
      "id_venta                    int64\n",
      "id_producto                 int64\n",
      "cantidad                    int64\n",
      "fecha_alta         datetime64[ns]\n",
      "fecha              datetime64[ns]\n",
      "nombre_cliente             object\n",
      "email                      object\n",
      "ciudad                     object\n",
      "medio_pago                 object\n",
      "nombre_producto            object\n",
      "categoria                  object\n",
      "precio_unitario             int64\n",
      "importe                     int64\n",
      "dtype: object\n",
      "\n",
      "‚ú® Preprocesamiento completado\n"
     ]
    }
   ],
   "source": [
    "if 'base_consolidada' in locals():\n",
    "    print('='*100)\n",
    "    print('üßπ PREPROCESAMIENTO - Limpieza y Transformaciones Finales')\n",
    "    print('='*100)\n",
    "    \n",
    "    # Crear copia para no modificar original hasta validar\n",
    "    base_final = base_consolidada.copy()\n",
    "    \n",
    "    # 1. Detectar y manejar duplicados\n",
    "    print('\\n1Ô∏è‚É£  Detecci√≥n de duplicados')\n",
    "    print('-'*80)\n",
    "    dup_count = base_final.duplicated().sum()\n",
    "    print(f'Filas duplicadas: {dup_count}')\n",
    "    if dup_count > 0:\n",
    "        print(f'  (Eliminando {dup_count} filas duplicadas)')\n",
    "        base_final = base_final.drop_duplicates()\n",
    "        print(f'  Nuevo tama√±o: {base_final.shape}')\n",
    "    \n",
    "    # 2. Renombrar columnas para mayor claridad y evitar colisiones\n",
    "    print('\\n2Ô∏è‚É£  Estandarizaci√≥n de nombres de columnas')\n",
    "    print('-'*80)\n",
    "    rename_map = {}\n",
    "    for col in base_final.columns:\n",
    "        # Aqu√≠ puedes definir transformaciones de nombres si es necesario\n",
    "        # Ejemplo: renombrar columnas que tengan sufijos _x o _y\n",
    "        if col.endswith('_x'):\n",
    "            rename_map[col] = col[:-2]\n",
    "        elif col.endswith('_y'):\n",
    "            rename_map[col] = col[:-2]\n",
    "    \n",
    "    if rename_map:\n",
    "        print(f'Columnas renombradas:')\n",
    "        for old, new in rename_map.items():\n",
    "            print(f'  {old:30s} ‚Üí {new}')\n",
    "        base_final.rename(columns=rename_map, inplace=True)\n",
    "    else:\n",
    "        print('‚úì No hay columnas con sufijos _x o _y')\n",
    "    \n",
    "\n",
    "    # 2b. Eliminar columnas duplicadas post-merge\n",
    "    print('\\n2b  Columnas duplicadas tras el merge')\n",
    "    print('-'*80)\n",
    "    duplicated_mask = base_final.columns.duplicated()\n",
    "    if duplicated_mask.any():\n",
    "        dup_names = base_final.columns[duplicated_mask]\n",
    "        dup_list = sorted({str(name) for name in dup_names})\n",
    "        base_final = base_final.loc[:, ~duplicated_mask]\n",
    "        print(f\" Columnas eliminadas: {dup_list}\")\n",
    "    else:\n",
    "        print(' No se detectaron columnas duplicadas')\n",
    "\n",
    "    # 3. Reordenar columnas de forma l√≥gica (primero IDs, luego datos descriptivos)\n",
    "    print('\\n3Ô∏è‚É£  Reorganizaci√≥n de columnas (orden l√≥gico)')\n",
    "    print('-'*80)\n",
    "    id_cols = [c for c in base_final.columns if 'id' in c.lower()]\n",
    "    date_cols = [c for c in base_final.columns if 'fecha' in c.lower() or 'date' in c.lower()]\n",
    "    money_cols = [c for c in base_final.columns if any(x in c.lower() for x in ['precio', 'importe', 'monto', 'total'])]\n",
    "    other_cols = [c for c in base_final.columns if c not in id_cols + date_cols + money_cols]\n",
    "    \n",
    "    new_order = id_cols + date_cols + other_cols + money_cols\n",
    "    base_final = base_final[[c for c in new_order if c in base_final.columns]]\n",
    "    print(f'‚úì Columnas reordenadas: {len(new_order)} columnas')\n",
    "    print(f'  - IDs (PK/FK): {len(id_cols)}')\n",
    "    print(f'  - Fechas: {len(date_cols)}')\n",
    "    print(f'  - Dinero (precios/importes): {len(money_cols)}')\n",
    "    print(f'  - Otros: {len(other_cols)}')\n",
    "    \n",
    "    # 4. Tipos de datos finales\n",
    "    print('\\n4Ô∏è‚É£  Validaci√≥n de tipos de datos')\n",
    "    print('-'*80)\n",
    "    print(base_final.dtypes)\n",
    "    \n",
    "    print('\\n‚ú® Preprocesamiento completado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d19523",
   "metadata": {},
   "source": [
    "## üìÑ 7. Exportaci√≥n a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "93309a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " EXPORTACION - Base Final a CSV\n",
      "====================================================================================================\n",
      "\n",
      " Exportando a: c:\\Users\\Asus\\Desktop\\Augusto Villegas - Proyecto Aurelion\\db\\final\\Base_Final_Aurelion.csv\n",
      " Exportacion exitosa\n",
      " Detalles del archivo:\n",
      "   - Nombre: Base_Final_Aurelion.csv\n",
      "   - Ruta: C:\\Users\\Asus\\Desktop\\Augusto Villegas - Proyecto Aurelion\\db\\final\\Base_Final_Aurelion.csv\n",
      "   - Tamano: 0.04 MB\n",
      "   - Registros: 343\n",
      "   - Columnas: 14\n",
      " Consolidacion completada exitosamente\n"
     ]
    }
   ],
   "source": [
    "if 'base_final' in locals():\n",
    "    print('='*100)\n",
    "    print(' EXPORTACION - Base Final a CSV')\n",
    "    print('='*100)\n",
    "    \n",
    "    # Definir ruta de exportacion\n",
    "    export_dir = DATA_FINAL_DIR\n",
    "    export_dir.mkdir(parents=True, exist_ok=True)\n",
    "    export_file = export_dir / 'Base_Final_Aurelion.csv'\n",
    "    \n",
    "    # Exportar a CSV\n",
    "    print(f\"\\n Exportando a: {export_file}\")\n",
    "    base_final.to_csv(export_file, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # Validar exportacion\n",
    "    if export_file.exists():\n",
    "        file_size_mb = export_file.stat().st_size / (1024**2)\n",
    "        print(' Exportacion exitosa')\n",
    "        print(' Detalles del archivo:')\n",
    "        print(f\"   - Nombre: {export_file.name}\")\n",
    "        print(f\"   - Ruta: {export_file.resolve()}\")\n",
    "        print(f\"   - Tamano: {file_size_mb:.2f} MB\")\n",
    "        print(f\"   - Registros: {len(base_final):,}\")\n",
    "        print(f\"   - Columnas: {len(base_final.columns)}\")\n",
    "    else:\n",
    "        print(' Error: El archivo no se creo correctamente')\n",
    "    \n",
    "    print(' Consolidacion completada exitosamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5bb41a",
   "metadata": {},
   "source": [
    "## üìã 8. Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b7d8979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " RESUMEN FINAL - CONSOLIDACION PROYECTO AURELION\n",
      "====================================================================================================\n",
      " Objetivo cumplido:\n",
      "    Se integraron los 4 dataframes limpios (clientes, ventas, detalle_ventas, productos)\n",
      "    Se aplicaron relaciones de clave primaria (PK) y foranea (FK)\n",
      "    Se valido integridad referencial\n",
      "    Se realizo preprocesamiento y limpieza adicional\n",
      "    Se exporto base consolidada a CSV\n",
      " Estadisticas finales:\n",
      "   - Registros en base final: 343\n",
      "   - Columnas integradas: 14\n",
      "   - Memoria usada: 0.14 MB\n",
      "   - Ubicacion archivo CSV: c:\\Users\\Asus\\Desktop\\Augusto Villegas - Proyecto Aurelion\\db\\final\\Base_Final_Aurelion.csv\n",
      " Proximos pasos:\n",
      "   1. Usar Base_Final_Aurelion.csv para analisis avanzados\n",
      "   2. Crear visualizaciones estrategicas\n",
      "   3. Desarrollar modelos predictivos o de segmentacion\n",
      "   4. Generar reportes ejecutivos\n",
      " Consolidacion finalizada correctamente\n"
     ]
    }
   ],
   "source": [
    "print('='*100)\n",
    "print(' RESUMEN FINAL - CONSOLIDACION PROYECTO AURELION')\n",
    "print('='*100)\n",
    "\n",
    "print(' Objetivo cumplido:')\n",
    "print('    Se integraron los 4 dataframes limpios (clientes, ventas, detalle_ventas, productos)')\n",
    "print('    Se aplicaron relaciones de clave primaria (PK) y foranea (FK)')\n",
    "print('    Se valido integridad referencial')\n",
    "print('    Se realizo preprocesamiento y limpieza adicional')\n",
    "print('    Se exporto base consolidada a CSV')\n",
    "\n",
    "print(' Estadisticas finales:')\n",
    "if 'base_final' in locals():\n",
    "    export_dest = DATA_FINAL_DIR / 'Base_Final_Aurelion.csv'\n",
    "    print(f\"   - Registros en base final: {len(base_final):,}\")\n",
    "    print(f\"   - Columnas integradas: {len(base_final.columns)}\")\n",
    "    print(f\"   - Memoria usada: {base_final.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "    print(f\"   - Ubicacion archivo CSV: {export_dest}\")\n",
    "\n",
    "print(' Proximos pasos:')\n",
    "print('   1. Usar Base_Final_Aurelion.csv para analisis avanzados')\n",
    "print('   2. Crear visualizaciones estrategicas')\n",
    "print('   3. Desarrollar modelos predictivos o de segmentacion')\n",
    "print('   4. Generar reportes ejecutivos')\n",
    "\n",
    "print(' Consolidacion finalizada correctamente')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
